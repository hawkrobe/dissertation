%!TEX root = ../dissertation.tex
\chapter{Conclusion}
\label{conclusion}

In this dissertation, we considered the computational challenge faced by agents trying to communicate in a variable and non-stationary landscape of meaning.
We first proposed a hierarchical Bayesian approach to semantic adaption that formalized three broad mechanisms exposed by the prior literature, and showed that a neural network instantiation of this model successfully adapted to human speakers in an interactive natural-language reference game task.
Because theories of adaption have been under-constrained by fine-grained empirical data, we then collected and used recent NLP techniques to analyze a large corpus from a replication of the classic tangrams task.
Inspired by insights from these analyses, we designed a targeted artificial language experiment to test our hypothesis that context shapes conventions and a graphical communication experiment to test the object- and interaction-specificity of conventions.
We conclude by discussing some broader questions raised by the theoretical perspective we have advanced here.

\paragraph{Generalization in language acquisition}

Throughout our work, we have assumed a discourse-level structure to an agent's priors. 
We assume there is uncertainty over how words are used \emph{in the given conversation, by the current partner}. 
However, there is a broader debate over the timescales at which lexicons and lexicon learning mechanisms operate.
In particular, these hierarchical learning mechanisms suggest the possibilityÂ of a developmental parallel.
Are the lexical learning mechanisms adults use to coordinate on local conventions \emph{within} an interaction the same as those supporting language-learning more broadly? 

Most laboratory tasks investigating cross-situational word learning only use a single speaker, and even sophisticated models of cross-situational word learning that account for pragmatic reasoning about speaker intentions \cite[e.g.]{FrankGoodmanTenenbaum09_Wurwur} tend to collapse over \emph{who} is talking. 
Yet, as we have argued throughout this work, there is substantial variability across different speakers. 
If the majority of child-directed speech only comes from a single primary caregiver, then the child may face a difficult generalization problem once they begin interacting with others. 
Upon hearing an unfamiliar word from a novel speaker, or a familiar word utterance with an unfamiliar meaning, it could be a quirk of that particular speaker \emph{or} indicative of a globally shared convention. 
There may therefore be substantial path-dependence in acquisition, as children develop their lexical prior and become better attuned to the overall variability in the population \cite<see>[Chap. 6]{Clark09_FirstLanguageAcquisition}. 

This slow-developing lexical prior is one of several explanation for why young children are so terrible at coordinating on local conventions in repeated reference games \cite{GlucksbergKraussWeisberg66_DevoRefGames,KraussGlucksberg77_SocialNonsocialSpeech}. 
When an experimenter feeds them the messages that adult speakers produced naturally, they had no trouble, even as they reduced down to one- or two-word utterances. When they played with one another, however, 
Kindergardeners continued to make errors even after 15-16 repetitions; children as old as fifth grade only improved with assistance from the experimenter and never approached the perfect levels of adult performance. 
Instead of beginning with the long indefinite descriptions full of hedges and modifiers that adults provide, nursery-school speakers began with short, highly idiosyncratic descriptions like \emph{Mother's dress}. 
If adult speakers' long hedge-filled messages are indeed motivated by lexical uncertainty, then perhaps young children have simply not obtained enough linguistic variability to calibrate their lexical prior. 
Alternatively, if the pragmatic reasoning required to produce informative utterance depends on theory of mind, then the high processing demands of the task may simply be inhibited performance \cite<e.g.>{SetohScottBaillargeon16_FalseBelief}. 
This remains an under-explored puzzle for future developmental research. 


\paragraph{Similarities and differences across communication modalities}

\begin{quote}
The oral modality is not well suited to conveying messages mimetically (i.e., iconically), even though that function is also important to human languages. This function is, however, very well served by the manual modality. \cite[p.155]{goldin-meadow_role_1999}
\end{quote}

More broadly, putting these results together with results from previous chapters raises a critical question about the role played by communication modality in convention formation.
While linguistic communication is powerful and prevalent, research on the dynamics of adaptation in other communication modalities, including graphical and gestural modalities, is important in several ways.
First, it is a core claim of our hierarchical learning model that the mechanisms underlying adaptation and convention formation are domain-general.
In other words, there's nothing special about spoken or written language; any ad hoc system that we use to communicate and coordinate with other minds should display similar learning dynamics because they are all trying to coordinate on meaning. 

Second, because this hierarchical learning model claims a critical role for the global priors we build up across many interactions with many individuals, we predict that different communication modalities should nevertheless display certain systematic differences in their dynamics.
For example, consider our reference game from Chapter 4 where the targets are complex, abstract geometric shapes like tangrams.
In the verbal modality, these shapes are highly innominate -- we don't have much experience naming or describing them with words, thus our global prior is rather weak and we expect local adaptation to play a much bigger role.
In the graphical modality, where you must communicate by drawing on a sketchpad, on the other hand, agents have a much stronger prior rooted in assumptions about shared perceptual systems and visual similarity (though see \citeNP{FanCommon2018}): explaining these similarity judgements poses its own challenges).
Other stimuli have precisely the opposite property: to distinguish between natural images of dogs, for instance, we may have very strong priors in the linguistic modality (e.g. `husky', `poodle', `pug', etc) but drawing the necessary fine distinctions in the graphical modality may be initially very costly, encouraging the formation of local conventions. 

Practically speaking, then, considering repeated reference games across different modalities is necessary to (1) test which adaptation effects, if any, are robust \& attributable to general mechanisms and (2) explain variance across settings where global priors and local adaptation trade off in different ways.
If we adhered solely to the verbal modality, we would be limited to a fairly narrow range of stimuli (e.g. abstract shapes/tangrams) where behavior in the lab isn't totally dominated by strong prior conventions people bring into the interaction. 
The clearest analogs to repeated linguistic reference games in the style of \cite{KraussWeinheimer64_ReferencePhrases} are Pictionary games like this ones used in this chapter.
where participants were given a whiteboard to draw on instead of an auditory channel to talk through \cite{TheisenEtAl10_SystematicityArbitrariness}.
For example, \citeA{GarrodFayLeeOberlanderMacLeod07_GraphicalSymbolSystems} used a set of 12 concept words with intuitively uncertain graphical priors as targets (``Robert de Niro'', ``poverty'').

Another modality-based manipulation is to attempt to destroy or scramble any meaningful priors that people might carry into the social interaction.
For example, \citeA{Galantucci05_EmergenceOfCommunication} introduced a novel `seismograph' interface for communication -- a stylus that could be moved side-to-side or lifted up or down to make contact with the sketch pad while the vertical dimension drifted downward at a constant rate.
The resulting messages consequently look nothing like the usual kinds of symbols people create: the relationship between motor actions and perceptual output is broken such that executing a familiar movement for a symbol or numeral instead produces an odd, wavy scribble.
Despite the relative lack of priors on signal meanings in this medium, people were nevertheless able to converge on successful signaling systems in repeated reference games \cite{RobertsGalantucci12_DualityOfPatterning,RobertsEtAl15_IconocityOnCombinatoriality}.
Other novel modalities used in iterated reference games include a `whistle' language where movements along a vertical touch bar slider correspond to changes in pitch \cite{VerhoefRobertsDingemanse15_Iconicity} and a visual analog where movements along the slider were presented visually \cite{VerhoefEtAl16_TemporalLanguage}.
A unified model of coordination in communication ought to be able to account for production and comprehension across these modalities simply by exchanging its encoder and decoder components.

\paragraph{Mechanisms for adaptation}

While we have focused on how participants coordinate on \emph{lexical} meaning, this is only one of many levels at which conventions may form. 
In more complex circumstances, there is often initial uncertainty not just about which of a small set of targets a particular message refers to, but how to represent the relevant targets of reference in the first place. 
Learning to communicate effectively may require discovering a lower-dimensional representation in which the targets of reference vary.
For instance, when using sketches to communicate about the identity of complex pieces of music \cite{HealeySwobodaUmataKing07_GraphicalLanguageGames}, a particular set of strokes could correspond to any number of properties (pitch, tempo, melody, rhythm, intensity) at any temporal granularity. 
This is made particularly clear in a classic maze game \cite{GarrodAnderson87_SayingWhatYouMean}: in order to give effective spatial directions, speakers had well-tuned lexical priors but had to coordinate on what space of \emph{referents} to use (e.g. paths, coordinates, lines, landmarks). 

Prior theories have assumed representations of lexical meanings are relatively fixed and the only learning taking place is how one's partner construes a multi-stable percept. 
For examine, this seems to be what \citeA{BrennanClark96_ConceptualPactsConversation} had in mind when they coined the term \emph{conceptual pact}, and \cite{stolk2016conceptual} have influentially argued that partners in communication construct shared conceptual spaces. 
Given present data it is not clear how these two sources of uncertainty could be teased apart, though certain kinds of conventions (e.g. proper names or acronyms) seem to rely more on binding new linguistic tokens to meanings than on constructing new conceptualizations.
Thus, we expect both levels of coordination are likely to play an important role. 
Our probabilistic model could be extended to handle additional levels of coordination by placing uncertainty over a hyper-parameter corresponding to the intended feature dimension that must be jointly inferred with the correspondence along that dimension. 

\paragraph{Conventions on networks}

Speakers use different language to talk with different partners in different communities \cite{auer_code-switching_2013}. 
For instance, when a scientist is talking to other scientists about their work, they know they can use efficient technical shorthand that they would avoid when talking to their non-expert friends and family. 
How and why does such community-specific shorthand form in the first place? 
And how do we represent which conventions are active for different (novel) partners? 
While our hierarchical model established mechanisms for convergence \emph{within} a community, a natural follow-up question is how people flexibly switch between different sets of conventions \emph{across} different communities.

Previous work has probed representations of community membership by manipulating the extent to which cultural background is shared between speaker and listener.
For example, \citeA{IsaacsClark87_ReferencesExpertsNovices} paired participants who had either lived in NYC or had never been there for a task referring to landmarks in the city (e.g. ``Rockefeller Center''). 
Within just a few utterances from a novel partner, people could infer whether they were playing with an expert or novice and immediately adjust their language use to be appropriate for this inferred identity. 
Social information about a partnerâs group can be so important that even players in artificial-language games react to the restrictions of social anonymity by learning to identify members of their community using distinctive signals \cite{roberts_experimental_2010}.

An important avenue for future work is to use large-scale networked experiments to evaluate the hypothesis that a hierarchical representation of conventions includes not just a partner-specific level and population-wide level but also intermediate community levels. 
This hypothesis can be formalized by including additional latent representations of community membership into our hierarchical model.
That is, in addition to updating our model of a particular \emph{partner} based on immediate feedback, even sparse observations of a partner's language use may license much broader inferences about their lexicon via diagnostic information about their social group or background. 
If someone's favorite song is an obscure B-side from an 80s hardcore band, you can make fairly strong inferences about what else they like to listen to and how similar they might be to you \cite{VelezEtAl16_Overlaps, GershmanEtAl17_StructureSocialInfluence}. 
Similarly, if someone casually refers to an obscure New York landmark you also recognize, you can safely update your beliefs about their lexicon to include a number of other conventions shared among New Yorkers. 
Lexica cluster within social groups, so inverting this relationship can yield rapid lexical learning from inferences about social group membership.

\paragraph{Closing thought}

Language is not some rigid body of knowledge that we acquire at an early age and deploy mechanically for the rest of our lives. 
Nor is its evolution a slow, inter-generational drift. 
It is a means for communication -- a shared interface between minds -- and must therefore adapt over the rapid timescales required by communication. 
In other words, we are constantly learning language. 
Not just one language, but a family of related languages, across every repeated interaction with every partner. 

%This source of lexical learning was explored in a study by \citeA{IsaacsClark87_ReferencesExpertsNovices} where novices and experts were paired for a repeated reference game using postcards of New York landmarks. Both directors and matchers could be either novices or experts, creating a 2x2 design. While a strong main effect of reduction was found across all pairings of experts and novices, they differed strikingly in their use of proper nouns (i.e. conventions shared by experts). For instance, over the course of the experiment, experts consistently used short messages with proper nouns (e.g. ``the Rockefeller Center'') when talking to other experts, while novice directors gradually adapted to expert matchers, doubling their use of proper names (and therefore drastically reducing the length of their utterances).

%Most striking, however, was the observation that directors had already adapted in the first few trials of the first round: by the fourth round expert directors were already using a proper noun three times more often when talking to other directors than in talking to novices. In fact, independent raters were presented with transcripts from the first two postcards and correctly judged the expertise of the two partners 84\% of the time. 
%This is a straightforward prediction of a hierarchical Bayesian model like the one we proposed in Chapter 2: given a latent group representation of New Yorkers, a director can make a strong prediction that if their partner belongs to this group, ``Rockefeller Center'' will belong to their lexicon with high probability. Hence, any interpretation failure is strong evidence that their partner is not in the group and is thus equally unlikely to recognize ``Citicorp Building'' or ``Brooklyn Bridge''. In this way, convention formation and social group inference are intimately intertwined. 


